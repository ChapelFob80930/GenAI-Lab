{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ChapelFob80930/GenAI-Lab/blob/main/Experiment_4_(DCGAN).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "b230O81YlNbR"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "6MhZ5wyZmSXe",
        "outputId": "5d017526-2660-40b4-f794-7e17b160e2f6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.18.0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "tf.__version__"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "import zipfile\n",
        "\n",
        "# Replace 'celebrity_case_dataset.zip' with the actual filename\n",
        "with zipfile.ZipFile('/content/celebrity case dataset.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('celebrity_face_dataset')\n"
      ],
      "metadata": {
        "id": "xa4dYegbLBcK"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "XTbIlMbpqxnA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b6f0a71-b48d-4513-ca89-670a0f3dfa73"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1800 files belonging to 17 classes.\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "\n",
        "# Define dataset path\n",
        "dataset_path = \"/content/celebrity_face_dataset/Celebrity Faces Dataset\"\n",
        "\n",
        "# Load dataset (assuming images are stored in folders by class)\n",
        "train_images = tf.keras.utils.image_dataset_from_directory(dataset_path, image_size=(128, 128), batch_size=128)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras-tuner"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oC9ZfTzaL2N4",
        "outputId": "3f0b8d37-7408-49ee-de94-4a463414037a"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting keras-tuner\n",
            "  Downloading keras_tuner-1.4.7-py3-none-any.whl.metadata (5.4 kB)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.11/dist-packages (from keras-tuner) (3.8.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from keras-tuner) (24.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from keras-tuner) (2.32.3)\n",
            "Collecting kt-legacy (from keras-tuner)\n",
            "  Downloading kt_legacy-1.0.5-py3-none-any.whl.metadata (221 bytes)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (1.26.4)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (0.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (3.12.1)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (0.14.1)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->keras-tuner) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->keras-tuner) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->keras-tuner) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->keras-tuner) (2025.1.31)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from optree->keras->keras-tuner) (4.12.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras->keras-tuner) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras->keras-tuner) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras->keras-tuner) (0.1.2)\n",
            "Downloading keras_tuner-1.4.7-py3-none-any.whl (129 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.1/129.1 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kt_legacy-1.0.5-py3-none-any.whl (9.6 kB)\n",
            "Installing collected packages: kt-legacy, keras-tuner\n",
            "Successfully installed keras-tuner-1.4.7 kt-legacy-1.0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "NKU4ZfwZmhOh"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "#import imageio\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import PIL\n",
        "from tensorflow.keras import layers\n",
        "import time\n",
        "import keras_tuner as kt\n",
        "from IPython import display"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "nd97zHW2mkqB",
        "outputId": "3be88acc-d239-4e1e-a6da-0d1f8f74dad4",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "module 'keras.api.datasets' has no attribute 'imagenet'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-8c008a1a6c6f>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;34m(\u001b[0m\u001b[0mtrain_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimagenet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: module 'keras.api.datasets' has no attribute 'imagenet'"
          ]
        }
      ],
      "source": [
        "(train_images, train_labels), (_, _) = tf.keras.datasets.imagenet.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "JH7pv3mqsnep",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74ab1567-3f04-4229-eca7-d53e0148d3ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "\u001b[1m29515/29515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "\u001b[1m26421880/26421880\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "\u001b[1m5148/5148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "\u001b[1m4422102/4422102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Train images shape: (60000, 28, 28)\n",
            "Train labels shape: (60000,)\n",
            "Test images shape: (10000, 28, 28)\n",
            "Test labels shape: (10000,)\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Load Fashion-MNIST dataset\n",
        "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.fashion_mnist.load_data()\n",
        "\n",
        "# Print dataset shapes\n",
        "print(\"Train images shape:\", train_images.shape)\n",
        "print(\"Train labels shape:\", train_labels.shape)\n",
        "print(\"Test images shape:\", test_images.shape)\n",
        "print(\"Test labels shape:\", test_labels.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "L8yeG4bEmmbG"
      },
      "outputs": [],
      "source": [
        "train_images = train_images.reshape(train_images.shape[0], 28, 28, 1).astype('float32')\n",
        "train_images = (train_images - 127.5) / 127.5  # Normalize the images to [-1, 1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "baukl8YSmn5P"
      },
      "outputs": [],
      "source": [
        "BUFFER_SIZE = 60000\n",
        "BATCH_SIZE = 256"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qcuoAg88uHsV"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "q1nM-uRfmpSI"
      },
      "outputs": [],
      "source": [
        "# Batch and shuffle the data\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices(train_images).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "ydsi0RM6mrku"
      },
      "outputs": [],
      "source": [
        "def make_generator_model():\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(layers.Dense(7*7*256, use_bias=False, input_shape=(100,)))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "\n",
        "    model.add(layers.Reshape((7, 7, 256)))\n",
        "    assert model.output_shape == (None, 7, 7, 256)  # Note: None is the batch size\n",
        "\n",
        "    model.add(layers.Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same', use_bias=False))\n",
        "    assert model.output_shape == (None, 7, 7, 128)\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "\n",
        "    model.add(layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n",
        "    assert model.output_shape == (None, 14, 14, 64)\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "\n",
        "    model.add(layers.Conv2DTranspose(1, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh'))\n",
        "    assert model.output_shape == (None, 28, 28, 1)\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 502
        },
        "id": "g2-hUA7mms16",
        "outputId": "23534b85-a3fc-4e03-a097-9a675d7c925f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f2aa4521010>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "generator = make_generator_model()\n",
        "\n",
        "noise = tf.random.normal([1, 100])\n",
        "generated_image = generator(noise, training=False)\n",
        "\n",
        "plt.imshow(generated_image[0, :, :, 0], cmap='gray')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "Q2Vt4joRmuYj"
      },
      "outputs": [],
      "source": [
        "def make_discriminator_model():\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same',\n",
        "                                     input_shape=[28, 28, 1]))\n",
        "    model.add(layers.LeakyReLU())\n",
        "    model.add(layers.Dropout(0.3))\n",
        "\n",
        "    model.add(layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same'))\n",
        "    model.add(layers.LeakyReLU())\n",
        "    model.add(layers.Dropout(0.3))\n",
        "\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(1))\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "skLzsMXAmwOh",
        "outputId": "56f186fe-d0f8-4b10-e5a6-c95ca10a48d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([[0.00190729]], shape=(1, 1), dtype=float32)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "discriminator = make_discriminator_model()\n",
        "decision = discriminator(generated_image)\n",
        "print (decision)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "daceMOJMmx7d"
      },
      "outputs": [],
      "source": [
        "\n",
        "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "FeexSSADmzd9"
      },
      "outputs": [],
      "source": [
        "def discriminator_loss(real_output, fake_output):\n",
        "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
        "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
        "    total_loss = real_loss + fake_loss\n",
        "    return total_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "rC8ObrxFm1A7"
      },
      "outputs": [],
      "source": [
        "def generator_loss(fake_output):\n",
        "    return cross_entropy(tf.ones_like(fake_output), fake_output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "hz-9Uuudm2cw"
      },
      "outputs": [],
      "source": [
        "generator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
        "discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "Ol-1GawQm3xe"
      },
      "outputs": [],
      "source": [
        "checkpoint_dir = './training_checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
        "                                 discriminator_optimizer=discriminator_optimizer,\n",
        "                                 generator=generator,\n",
        "                                 discriminator=discriminator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "GfsGgPyGm5UJ"
      },
      "outputs": [],
      "source": [
        "EPOCHS = 50\n",
        "noise_dim = 100\n",
        "num_examples_to_generate = 16\n",
        "\n",
        "# You will reuse this seed overtime (so it's easier)\n",
        "# to visualize progress in the animated GIF)\n",
        "seed = tf.random.normal([num_examples_to_generate, noise_dim])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "yPAqIf-qm65k"
      },
      "outputs": [],
      "source": [
        "# Notice the use of `tf.function`\n",
        "# This annotation causes the function to be \"compiled\".\n",
        "@tf.function\n",
        "def train_step(images):\n",
        "    noise = tf.random.normal([BATCH_SIZE, noise_dim])\n",
        "\n",
        "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "      generated_images = generator(noise, training=True)\n",
        "\n",
        "      real_output = discriminator(images, training=True)\n",
        "      fake_output = discriminator(generated_images, training=True)\n",
        "\n",
        "      gen_loss = generator_loss(fake_output)\n",
        "      disc_loss = discriminator_loss(real_output, fake_output)\n",
        "\n",
        "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
        "\n",
        "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "Bp3KZ4_tm8L7"
      },
      "outputs": [],
      "source": [
        "def train(dataset, epochs):\n",
        "  for epoch in range(epochs):\n",
        "    start = time.time()\n",
        "\n",
        "    for image_batch in dataset:\n",
        "      train_step(image_batch)\n",
        "\n",
        "    # Produce images for the GIF as you go\n",
        "    display.clear_output(wait=True)\n",
        "    generate_and_save_images(generator,\n",
        "                             epoch + 1,\n",
        "                             seed)\n",
        "\n",
        "    # Save the model every 15 epochs\n",
        "    if (epoch + 1) % 15 == 0:\n",
        "      checkpoint.save(file_prefix = checkpoint_prefix)\n",
        "\n",
        "    print ('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))\n",
        "\n",
        "  # Generate after the final epoch\n",
        "  display.clear_output(wait=True)\n",
        "  generate_and_save_images(generator,\n",
        "                           epochs,\n",
        "                           seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "F8mZkUTXm9i_"
      },
      "outputs": [],
      "source": [
        "def generate_and_save_images(model, epoch, test_input):\n",
        "  # Notice `training` is set to False.\n",
        "  # This is so all layers run in inference mode (batchnorm).\n",
        "  predictions = model(test_input, training=False)\n",
        "\n",
        "  fig = plt.figure(figsize=(4, 4))\n",
        "\n",
        "  for i in range(predictions.shape[0]):\n",
        "      plt.subplot(4, 4, i+1)\n",
        "      plt.imshow(predictions[i, :, :, 0] * 127.5 + 127.5, cmap='gray')\n",
        "      plt.axis('off')\n",
        "\n",
        "  plt.savefig('image_at_epoch_{:04d}.png'.format(epoch))\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "z022eF2tm-3r"
      },
      "outputs": [],
      "source": [
        "train(train_dataset, EPOCHS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "gRpgEf83nAww"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JL1FWI9JODDx"
      },
      "execution_count": 38,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}